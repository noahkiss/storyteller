---
phase: 02-creative-library-story-setup
plan: 06
type: execute
wave: 4
depends_on: ["02-02", "02-03", "02-04"]
files_modified:
  - src/services/ai-conversation.ts
  - src/hooks/use-ai-conversation.ts
  - src/components/story-setup/PremiseWorkspace.tsx
  - src/components/story-setup/PremiseWorkspace.css
autonomous: true

must_haves:
  truths:
    - "User can input a story premise and have a back-and-forth conversation with the AI"
    - "AI starts in Socratic mode (asking questions) and shifts to suggestive when user seems stuck"
    - "Conversation happens in the textarea, not a separate chat interface"
    - "When premise is developed enough, AI can extract characters, settings, and outline structure"
    - "Extracted assets can be accepted into the library and story outline"
  artifacts:
    - path: "src/services/ai-conversation.ts"
      provides: "Adaptive conversation state machine (Socratic/suggestive/extracting)"
      exports: ["ConversationStateMachine", "generateConversationPrompt"]
    - path: "src/hooks/use-ai-conversation.ts"
      provides: "React hook wrapping the conversation state machine with LLM integration"
      exports: ["useAIConversation"]
    - path: "src/components/story-setup/PremiseWorkspace.tsx"
      provides: "Premise refinement UI in left pane"
  key_links:
    - from: "src/hooks/use-ai-conversation.ts"
      to: "src/services/ai-conversation.ts"
      via: "state machine import"
      pattern: "ConversationStateMachine"
    - from: "src/hooks/use-ai-conversation.ts"
      to: "src/services/llm-client.ts"
      via: "LLM generation"
      pattern: "generateStream"
    - from: "src/components/story-setup/PremiseWorkspace.tsx"
      to: "src/hooks/use-ai-conversation.ts"
      via: "hook usage"
      pattern: "useAIConversation"
---

<objective>
Build the AI-assisted premise refinement system with adaptive conversation. Users input a story premise in the textarea and engage in back-and-forth with the AI, which adapts between Socratic questioning and suggestive guidance. When the premise is developed, the AI extracts characters, settings, and outlines.

Purpose: Satisfies SETUP-01 (premise refinement through AI conversation) and SETUP-03 (collaborative building of characters/settings/plot during setup). This is the primary story creation entry point.
Output: Conversation state machine, premise workspace UI, asset extraction from developed premises.
</objective>

<execution_context>
@/home/flight/.claude/get-shit-done/workflows/execute-plan.md
@/home/flight/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-creative-library-story-setup/02-CONTEXT.md
@.planning/phases/02-creative-library-story-setup/02-RESEARCH.md
@.planning/phases/02-creative-library-story-setup/02-02-SUMMARY.md
@.planning/phases/02-creative-library-story-setup/02-03-SUMMARY.md
@.planning/phases/02-creative-library-story-setup/02-04-SUMMARY.md
@src/services/llm-client.ts
@src/hooks/use-llm-stream.ts
@src/stores/settings-store.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Conversation state machine and AI conversation service</name>
  <files>src/services/ai-conversation.ts</files>
  <action>
Create `src/services/ai-conversation.ts`:

Define conversation mode type: `'socratic' | 'suggestive' | 'extracting'`

Define conversation state interface:
```typescript
interface ConversationState {
  mode: ConversationMode;
  turnCount: number;
  stuckSignals: Array<{ turn: number; signal: string }>;
  conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }>;
  extractedAssets: {
    characters: Array<{ name: string; description: string }>;
    settings: Array<{ name: string; description: string }>;
    plotPoints: string[];
  } | null;
}
```

Implement `createConversationState()` — factory function returning initial state (mode='socratic', empty history).

Implement `updateConversationMode(state: ConversationState, userInput: string): ConversationState`:
- Detect stuck signals: /i don't know/i, /not sure/i, /help/i, /stuck/i, /give me (some )?ideas/i
- Per research pitfall #5: require 2+ signals in last 3 turns to switch to suggestive (avoid premature transition)
- Explicit help request ("give me ideas", "help me") switches immediately
- Track turn count and increment

Implement `generateConversationPrompt(state: ConversationState, userInput: string, storyContext?: string): string`:
- Builds the system prompt based on current mode:

**Socratic mode:**
"You are a story development assistant. The user is developing a story premise. Ask thoughtful clarifying questions to help them flesh out their idea. Focus on: characters and their motivations, relationships between characters, emotional core of the story, key settings and their atmosphere. Be concise — one question at a time. Be encouraging. Don't suggest plot ideas unless asked."

**Suggestive mode:**
"You are a story development assistant. The user is developing a story premise and needs some inspiration. Based on what they've shared, suggest 2-3 specific, concrete ideas they could explore. Frame as possibilities, not prescriptions. Focus on slice-of-life elements: character dynamics, everyday settings, emotional themes."

**Extracting mode:**
"Based on the conversation about this story, extract the following in a structured format:

CHARACTERS:
- Name: description, role, key traits

SETTINGS:
- Name: description, atmosphere, character associations

OUTLINE:
- Chapter/Scene: summary, characters present, setting, mood

Format clearly so the user can review and edit."

- Build messages array: system prompt + conversation history + current user input
- Return the messages array (to be passed to LLM)

Implement `shouldExtract(state: ConversationState): boolean`:
- Returns true when: turn count >= 4 AND conversation history has at least 2 assistant responses with substantive content (> 50 chars each)
- This determines when to show the "Extract Assets" button

Implement `parseExtractedAssets(aiResponse: string): ConversationState['extractedAssets']`:
- Simple regex/string parsing of the AI's extraction response
- Look for "CHARACTERS:" section and parse Name: description lines
- Look for "SETTINGS:" section similarly
- Look for "OUTLINE:" section and parse scene entries
- Return structured data or null if parsing fails
- Be lenient — if the AI format doesn't match exactly, extract what's possible
  </action>
  <verify>
`npm run build` passes. State machine transitions correctly: socratic → suggestive after stuck signals. Prompt generation produces appropriate system messages for each mode.
  </verify>
  <done>Conversation state machine handles mode transitions with appropriate thresholds. Prompt generation produces mode-appropriate system messages. Asset extraction parsing handles structured AI output.</done>
</task>

<task type="auto">
  <name>Task 2: AI conversation hook and premise workspace UI</name>
  <files>src/hooks/use-ai-conversation.ts, src/components/story-setup/PremiseWorkspace.tsx, src/components/story-setup/PremiseWorkspace.css</files>
  <action>
Create `src/hooks/use-ai-conversation.ts`:

This hook integrates the conversation state machine with the existing LLM client:

```typescript
export function useAIConversation(storyId: string | null)
```

Returns:
- `state: ConversationState` — current conversation state
- `isGenerating: boolean` — whether AI is currently responding
- `sendMessage(userInput: string): void` — send user message, get AI response
- `extractAssets(): void` — trigger asset extraction mode
- `canExtract: boolean` — whether the "Extract" button should be shown
- `acceptCharacter(index: number): void` — accept an extracted character into the library
- `acceptSetting(index: number): void` — accept an extracted setting into the library
- `acceptOutline(): void` — accept extracted outline into story's outline
- `reset(): void` — reset conversation

Implementation:
- Uses `useSettingsStore` to get LLM connection settings
- Uses the OpenAI SDK (imported from llm-client) for non-streaming generation (conversation responses should be complete, not streamed, for this use case — simpler UX)
- Actually, per user decision, everything happens in the textarea. So the conversation is NOT a chat sidebar — it's a document in the textarea where user and AI take turns writing. Format:

```markdown
# Story Premise Development

## Your Premise
(User writes here)

## AI Response
(AI writes here)

## Your Response
(User writes here)

## AI Response
(AI continues...)
```

Alternative simpler approach: The textarea shows the full conversation as a growing document. User types at the bottom, clicks "Send" (or presses a button), AI response appends to the document. This is basically a chat log rendered as markdown in the textarea.

- When user sends a message: append their message to the conversation document, call LLM, append AI response
- Store conversation as the story's premise field (via useUpdateStory)
- Use streaming for AI responses (use `useLLMStream` from Phase 1) for responsive feel
- After extraction: parsed assets are stored in local state, shown in the left pane premise workspace

Create `src/components/story-setup/PremiseWorkspace.tsx`:

This is a left-pane component shown when a story is in 'setup' status:

1. **Mode selector** — "Free-form" or "Guided" buttons at the top (per user decision)
   - Free-form: user types premise directly in textarea
   - Guided: AI starts with a structured first question

2. **Send button** — sends the latest user input to the AI conversation
   - Shows loading indicator while AI is generating
   - Disabled when no new user input or currently generating

3. **"Extract Assets" button** — visible when canExtract is true
   - Triggers extraction mode, AI produces structured output
   - Shows extraction results below

4. **Extraction results** — when extractedAssets is populated:
   - List of characters with "Accept" button each
   - List of settings with "Accept" button each
   - Outline preview with "Accept" button
   - Accepting creates the item in the library/outline tables

5. **"Move to Outlining" button** — transitions story status from 'setup' to 'outlining'

Style: dark theme, compact layout for left pane. Extraction results use cards similar to LibraryItemCard.

The textarea in the right pane shows the conversation document. This component in the left pane provides the controls and extraction results.
  </action>
  <verify>
`npm run build` passes. PremiseWorkspace renders with mode selector and send button. Conversation state machine drives the UI correctly.
  </verify>
  <done>AI conversation hook connects state machine to LLM. PremiseWorkspace provides controls for premise refinement in left pane. Extraction results show parsed characters/settings/outline with accept buttons. SETUP-01 and SETUP-03 requirements satisfied.</done>
</task>

</tasks>

<verification>
- `npm run build` succeeds
- Conversation state machine: socratic → suggestive after stuck signals, extracting on demand
- Premise document grows in textarea as conversation progresses
- "Extract Assets" shows parsed characters, settings, outline
- Accepting extracted items creates library entries and story outline
- Mode selector switches between free-form and guided approaches
</verification>

<success_criteria>
Users can develop a story premise through AI conversation, with the AI adapting between Socratic and suggestive modes. Developed premises produce extractable creative assets. SETUP-01 (premise refinement) and SETUP-03 (collaborative building) requirements satisfied.
</success_criteria>

<output>
After completion, create `.planning/phases/02-creative-library-story-setup/02-06-SUMMARY.md`
</output>
